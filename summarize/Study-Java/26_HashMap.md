---
title: 26_HashMap
date: 2022-08-11
author: yincy
---

### HashMap

##### 1、HashMap 的工作原理是什么？

​	HashMap 底层是采用的数组+链表/红黑树的数据结构来实现的，数组中的每一个元素都是一个链表结构，而链表中的每一个节点又是一个 Node 类型，Node 中又包含了要保存的 key 和 value 以及 hash 和下一个元素 next。

​	put() 方法：首先会先拿到 哈希表：Node[] table，然后判断哈希表是否为 null 或者长度为 0，如果是，则通过 resize() 方法进行数组的初始化操作；否则会根据 key 的哈希值计算出元素在数组中要插入的下标位置，计算公式为（n-1）& hash，n 为数组的长度，然后判断该位置的元素是否为 null，如果为 null，说明该下标位置还没有元素，则直接创建 Node 对象，插入到该位置；否则，再比较要添加的元素的 hash 值与该位置元素的 hash 值是否相等，如果相等，再比较两个元素的 key 是否相等，或者该元素的 key 不为 null，并且两个元素的 key 相等，那么就将该位置的元素的值覆盖；如果目标位置的 key 存在，还与要添加的元素的 key 不同，并且该位置的元素的类型为 红黑树，则插入到红黑树中，否则说明该位置为链表结构，然后遍历该链表，在链表的尾部插入，并且判断链表长度是否达到了链表转为红黑树的长度阈值 8，如果达到了，则通过 treeifBin() 方法将链表转为红黑树，当然在该方法内部还会判断当前数组是否达到了链表转红黑树时，数组的最大长度64，如果达到了转换，如果没达到就不转换，而是通过 resize() 方法对数组进行扩容，如果都没有的话，则会在最后根据添加后 HashMap 中的键值对个数是否达到了扩容阈值（数组容量*加载因子）如果达到了进行扩容 ；如果遍历到某个节点时，发现 key 相同，则直接覆盖然后退出循环，并返回被替换的值

​	get() 方法：首先会判断数组是否不为空，并且数组的长度大于0，并且数组的 (n - 1) & hash 位置的元素不为 null，如果这个条件不满足的话，直接返回 null，否则进行下面的判断：如果目标索引位置的元素就是要找的元素（先比较hash值，如果hash值相同再通过 equals() 比较），则直接返回；如果目标索引位置元素的下一个节点不为空，判断：如果类型是红黑树，则从红黑树中查找；否则就是链表，遍历链表查找目标元素。

​	resize() 方法：先拿到扩容前的数组，获取扩容前的数组的大小和阈值；如果原来数组的大小大于0，判断是否超过了最大值（超过了就不再扩容了），然后扩大容量为当前容量的两倍，但不能超过最大值（2的30次方）；如果当前数组没有数据，使用初始化的值（16）；否则（初始化的值为0，则使用默认的初始化容量：16）（第一次的扩容阈值为：0.75 * 16 = 12）；【后面就是根据新容量创建新的 Node[]，然后进行复制，最终将新的 Node[] 返回】。



总结下来：利用 key 的 hash 值来计算出元素的下标位置，然后再通过 equals() 比较，解决 hash 冲突的问题

---



##### 2、Hash 表链表超长以后转化成红黑树，为什么会使用红黑树？

​	红黑树是二叉查找树的一种，它的查找算法就相当于是二分的查找，红黑树的时间复杂度 O(log n) 在数据比较多的时候，会比链表的查询的时间复杂度 O(n) 要好很多。

---



##### 3、你认为 HashMap 可不可以不使用链表，而直接使用红黑树，或者二叉搜索树、AVL树？

​	我认为 HashMap 之所以没有选择一开始就使用红黑树可能是因为时间和空间的折中考虑，在 Hash 冲突比较小的时候，即使转化为红黑树之后，在时间复杂度中所产生的效果也并不是特别大，而且在 put 的时候效率可能会降低，毕竟每次 put 都要进行非常复杂的红黑树的这种旋转算法来进行旋转操作，另外在空间上的话，每个节点都需要维护更多的一个指针，这就显得有些得不偿失了，最后就是 HashMap 之所以选择红黑树，而不是二叉搜索树，我认为最主要的原因是二叉搜索树在一些极端的情况下，他会退化为一个链表结构；而红黑树是一种平衡树，它可以防止这种退化，所以可以保持平衡，因为红黑树又不像其他的完全的平衡二叉树那样有严格的平衡条件，所以呢，红黑树插入效率要比完全的平黑二叉树要高，所以的话，HashMap 在选择红黑树既可以避免极端情况下的退化，也可以兼顾查询和插入的这种效率。

---



##### 4、HashMap 是线程安全的嘛

​	HashMap 在设计的时候是针对于单线程环境下来设计的，所以在多线程环境下，它不是线程安全的。

---



##### 5、多线程并发环境下，如果需要一个 Hash 结构，你如何实现？

​	如果在多线程并发环境下，我们可以使用 ConcurrentHashMap 来实现这样的一个需求

---



##### 6、ConcurrentHashMap 底层实现原理的理解

​	ConcurrentHashMap （1.7）：它的底层是使用数组加链表来实现的，然后使用了一种分段锁来保证线程安全，它是将数组分成了 16 段，也就是给每个 Segment 来配一把锁，然后再读每个 Segment 的时候就要先获取对应的锁，所以呢它是最多能有 16 个线程并发去操作。

​	ConcurrentHashMap  （1.8）：它跟 HashMap 一样也引入了这种红黑树的这个数据结构，同时在并发处理方面，不再使用分段锁的方式，而是采用 CAS 加 synchronized 关键字的这样方式来实现一种更加细粒度的锁，相当于是把这个锁的控制，控制在了这种更加细粒度的哈希桶的这个级别，然后在写入键值对的时候，这个可以锁住哈希桶的这种链表的这种这个头节点，就不会影响到其他的哈希桶的写入，从而去提高对并发的这种处理能力。

---



##### 7、ConcurrentHashMap 可以使用 ReentrantLock 作为锁嘛

​	理论上来件的话应该是可以的，但是我认为这个 synchronized 关键字会更好一点吧，因为在 1.6 之后对synchronized 关键字也进行了一些优化，它里面引入了偏向锁、轻量级锁、重量级锁，那么这些在 ReentrantLock 中是没有的，并且随着 JDK 版本的这个升级，这个 synchronized 也在进一步的进行优化，因为这个 ReentrantLock 是使用 Java 代码来实现的，所以在之后的话也很难有特别大的一种提升空间，所以的话，让我选的话，我会优先选择 synchronized，然后再考虑 ReentrantLock。

---



##### 8、synchronized 关键字对于锁的优化的介绍

​	synchronized 它默认是采用的偏向锁，然后在程序运行中始终是只有一个线程去获取synchronized 的这个锁，那么 Java 对象中的话，会记录一个线程的 ID，所以呢，我们在下次再获取这个 synchronized 的锁的时候，只需要去比较这个线程 ID 就行了，在运行的过程中如果出现第二个线层去请求 synchronized 锁的时候，这里就分两种情况：在没有发生并发竞争锁的情况下，这个 synchronized 就会自动升级为轻量级锁，这个时候第二个线程就会尝试以自旋锁的方式来获取锁，因为很快就能拿到锁，所以第二个线程也不会阻塞，但是如果出现了这种两个线程竞争锁的情况的话，这个 synchronized 它会升级为重量级锁，那么这个时候就是只会有一个线程能够获取到锁，那么另外一个线程它会阻塞，然后要等待第一个线程释放锁之后，才能去拿到锁

​	

---

