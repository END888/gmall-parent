---
title: 面试题10_RabbitMQ
date: 2022-08-16
author: yincy
---

### 面试题10_RabbitMQ



#### 1、消息队列的作用和使用场景？

**异步处理**：用户注册后，发送注册邮件和注册短信。用户注册完成后，提交任务到 MQ，发送模块并行获取 MQ 中的任务。

**系统解耦**：比如用注册完成，再加一个发送微信通知。只需要新增发送微信消息模块，从 MQ 中读取任务，发送消息即可。无

需改动注册模块的代码，这样注册模块与发送模块通过 MQ 解耦。

**流量削峰**：秒杀和抢购等场景经常使用 MQ 进行流量削峰。活动开始时流量暴增，用户的请求写入MQ，超过 MQ 最大长度丢

弃请求，业务系统接收 MQ 中的消息进行处理，达到流量削峰、保证系统可用性的目的。

**日志处理**：日志采集方收集日志写入 kafka 的消息队列中，处理方订阅并消费 kafka 队列中的日志数据。

**消息通讯**：点对点或者订阅发布模式，通过消息进行通讯。如微信的消息发送与接收、聊天室等。

---

#### 2、简单介绍一些 RabbitMQ 的架构？

消息的发送消息流程：

1、生产者和Rabbitmq服务端建立连接 connection，然后获取通道 channel

2、生产者发送消息发送给指定的虚拟机 Virtual Host 中的交换机 Exchange

3、交换机 Exchange 根据消息的 routingKey 将消息转发给指定的队列 Queue

消费者消费消息流程：

1、消费者 Consumer和Rabbitmq服务端建立连接 connection，然后获取通道 channel

2、消费者 Consumer 监听指定的队列 queue

3、一旦队列 queue 有消息了此时就会把消息推送给指定的消费者 Consumer

---

#### 3、RabbitMQ 中的交换机类型有哪些？

主要有以下4种：

**fanout**: 把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。

**direct**:把消息路由到BindingKey和RoutingKey完全匹配的队列中。

**topic**: 匹配规则：

​	RoutingKey 为一个 点号'.': 分隔的字符串。比如: java.xiaoka.show

​	BindingKey和RoutingKey一样也是点号“.“分隔的字符串。

​	BindingKey可使用 * 和 # 用于做模糊匹配，*匹配一个单词，#匹配多个或者0个

**headers**:不依赖路由键匹配规则路由消息。是根据发送消息内容中的headers属性进行匹配。性能差，基本用不到。

---

#### 2、RabbitMQ 如何保证消息的顺序执行？

消息队列中的若干消息如果是对同一个数据进行操作，并且这些操作具有前后的顺序关系，那么就必须要按前后的顺序执行，否则就会造成数据异常，比如通过 mysql binlog 进行两个数据的数据同步，由于对数据库的数据操作是具有顺序性的，如果操作顺序搞反，就会造成一些严重性问题，比如数据库对一条数据一次进行了 插入-->更新-->删除操作，这个顺序必须是这样的，如果在同步过程中，消息的顺序变成了删除-->插入-->更新，那么原本应该被删除的数据，就没有被删除，造成数据的不一致问题。

举例场景：

RabbitMQ：【1】一个 queue，有多个 Consumer 去消费，这样就会造成顺序的错误，Consumer 从 MQ 里面读取数据是有序的，但是每个 Consumer 的执行时间是不固定的，无法保证先读到消息的 Consumer 一定先完成操作，这样就会出现消息并没有按照顺序执行，造成数据顺序错误。【2】一个 queue 对应一个 Consumer，但是 Consumer 里面进行了多线程消费，这样也会造成消息消费顺序错误。

解决方案：【1】拆分多个 queue，每个 queue 一个Consumer，就是多一些 queue 而已，确实是麻烦点；这样也会造成吞吐量下降，可以在消费内部采用多线程的方式去消费。一个 queue 对应一个 Consumer；【2】或者就一个 queue 只能对应一个 Consumer，然后这个 Consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理，一个 queue 对应一个 Consumer，采用多线程

---

1、将多个消息发送到一个队列中，队列本身就是先进先出的结构

2、避免多消费者并发消费同一个 queue 中的消息。

---

#### 3、如何使用 RabbitMQ 解决分布式事务？

分布式事务：不同的服务操作不同的数据源（库或表），保证数据一致性的问题；

解决：采用 RabbitMQ 消息最终一致性的解决方案解决分布式事务问题。

分布式事务场景：

1、电商项目中的商品库和 ES 库数据同步问题。

2、电商项目中：支付-->订单-->库存，一系列操作，进行状态更改等。

在互联网应用中，基本都会有用户注册的功能，在注册的同时，我们会做出如下操作：

收集用户录入信息，保存到数据向用户的手机或者邮箱发送验证码等等...，如果是传统的集中式架构，实现这个功能非常简单：开启一个本地事务，往本地数据库中插入一条用户数据，发送验证码，提交事务；但是在分布式架构中，用户和发送验证码是两个独立的服务，他们都有各自的数据库，那么就不能通过本地事务保证操作的原子性，这时我们就需要用到 RabbitMQ 来为我们实现这个需求。在用户进行注册操作的时候，我们为该操作创建一条消息，当用户信息保存成功时，把这条消息发送到消息队列，验证码系统会监听消息，一旦接收到消息，就会给该用户发送验证码。

---

#### 4、RabbitMQ 如何确保消息可靠性？

发送方确认模式

将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。

一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。

如果 RabbitMQ 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。

发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。



1、生产者：RabbitMQ 提供 transaction 事务和 confirm 模式来确保生产者不丢消息；transaction 事务机制就是说：发送消息前， 开启事务，然后发送消息，如果发送过程中出现什么异常，事务就会回滚，然后这种方式有个缺点，就是吞吐量下降；confirm 模式用的居多：一旦 channel 进入 confirm 模式，所有在该信道上发布的消息都讲会被指派一个唯一的 ID（从1开始），一旦消息被投递到所有匹配的队列之后，RabbitMQ 就会发送一个 ACK 给生产者（包含消息的唯一 ID），这就使得生产者知道消息已经正确到达目的队列了；如果 RabbitMQ 没能处理该消息，则会发送一个 Nack 消息可以进行重试操作，由于发送方确认模式是异步的，所以生产者应用程序在等待确认的同时，可以继续发送消息。

2、消息队列本身：可以进行消息持久化，即使 RabbitMQ 挂了，重启后也能恢复数据，如果要进行消息持久化，那么需要对以下 3 中实体均配置持久化【1】Exchange，声明 exchange 时设置持久化（durable=true）并且不自动删除（autoDelete=false）；【2】Queue，声明 queue 时设置持久化（durable=true）并且不自动删除（autoDelete=false）；【3】Message，发送消息时通过设置 deliveryMode=2 持久化消息。

3、消费者：消费者丢数据一般是因为采用了自动确认消息模式，消费者在收到消息之后，处理消息之前，会自动回复 RabbitMQ 已收到消息；如果这时处理消息失败，就会丢失该消息；改为手动确认消息即可！手动确认模式下消费失败时，不将其重新放入队列（确认重试也不会成功的情形），打印错误信息后，通知相关人员，人工介入处理。



---

消息丢失的发送的时机：

1、生产者发送消息的时候，由于网络抖动导致消息没有发送成功

2、消息发送到Rabbitmq的以后，Rabbitmq宕机了

3、消费者获取到MQ中的消息以后，还没有及时处理，此时消费者宕机了

解决方案：

1、生产者发送消息：主流的MQ都有**确认机制或事务机制**，可以保证生产者将消息送达到 MQ。如 RabbitMQ 就有事务模式

和 confirm模式。

2、MQ 丢失消息：开启 MQ 的持久化配置(消息、队列都需要进行持久化)。

3、消费者丢失消息：改为手动确认模式，消费者成功消费消息再确认。

---

#### 5、如何防止 RabbitMQ 消息重复消费？

正常情况下，消费者在消费消息的时候，消费完毕后，会发送一个确认消息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除；(消费者的 消息应答机制)但是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他的消费者。

解决思路是：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息的 幂等性；

在消息生产时，MQ内部针对每条生产者发送的消息生成一个inner-msg-id，作为去重和幂等的依据（消息投递失败并重传），避免重复的消息进入队列；
在消息消费时，要求消息体中必须要有一个bizId（对于同一业务全局唯一，如支付ID、订单ID、帖子ID等）作为去重和幂等的依据，避免同一条消息被重复消费。
这个问题针对业务场景来答分以下几点（还是要在消费方做数据存储时 手动去重）：

如果消息是做数据库的insert操作，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。
如果消息是做redis的set的操作，不用解决，因为无论set几次结果都是一样的，set操作本来就是幂等操作。
如果以上两种情况还不行，可以准备一个第三方介质,来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将<id,message>以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。

---



消息重复消费的原因：

1、生产者发送消息的时候，在指定的时间只能没有得到服务端的反馈，此时触发了重试机制，在Rabbitmq服务端就会出现重

复消费，那么消费者在进行消费的时候就出现了重复消费。

2、消费者消费完毕以后，消费方给MQ确认已消费的反馈，MQ 没有成功接受。该消息就不会从Rabbitmq删除掉，那么消费

者再一次获取到了消息进行消费。



MQ是无法保证消息不被重复消费的，只能业务系统层面考虑。不被重复消费的问题，就被转化为消息**消费的幂等性**的问题。幂

等性就是指一次和多次请求的结果一致，多次请求不会产生副作用。

保证消息消费的幂等性可以考虑下面的方式：

① 给消息生成全局 id，消费成功过的消息可以直接丢弃

② 消息中保存业务数据的主键字段，结合业务系统需求场景进行处理，避免多次插入、是否可以根据主键多次更新而并不影响

结果等



---



#### 6、如果解决消息队列的延时以及过期失效问题？消息队列满了之后该如何处理？有几百万的消息持续积压几小时，说说如何解决？

方案分析：

该问题，其本质针对的场景都是说，可能你的消费端出了问题，不消费了，或者消费的极其缓慢；另外还有可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是整个这就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如 RabbitMQ 设置了消息过期时间后就没了该怎么办？所以这种问题线上常见的，一般不出，一出就是大问题，一般常见于，举个例子：消费端每次消费之后要写 mysql，结果 mysql 挂了，消费端挂掉了，导致消费速度及其慢。

分析1+话术：

如果积压了几百万到上千万的数据，即使消费者恢复了，也需要一段时间才能恢复过来，一般这个时候，只能操作临时紧急扩容了：

【1】先修复 Consumer 的问题，确保能恢复消费速度，然后将现有的 Consumer 都停掉，【2】然后新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍或者 20 倍的 queue 数量，【3】然后写一个临时的分发数据的 Consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue，【4】接着临时征用 10 倍的机器来部署 Consumer，每一批 Consumer 消费一个临时 queue 的数据，【5】这种做法相当于是临时将 queue 资源和 Consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据，【6】等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的 Consumer 机器来消费消息。

分析2+话术：

RabbitMQ 是可以设置过期时间的，就是 TTL，如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了，那这就是第二个坑了，这就不是说数据会大量积压在 RabbitMQ 里，而是大量的数据会直接搞丢；这个情况下，就不是说要增加 Consumer 消费积压的消息，因为实际上没啥积压，而是丢了大量的消息，我们可以采取一个方案，就是批量重导，这个之前线上也有类似的场景干过，就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大奖一起喝咖啡熬夜到晚上 12 点以后，用户都睡觉了，这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 RabbitMQ 中，把白天丢的数据给它补回来，也只能是这样了；假设1万个订单积压在 RabbitMQ 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 RabbitMQ 里去再补一次；

分析3+话术：

如果走的方式是消息积压在 RabbitMQ 里，那么如果你很长时间都没处理掉，此时导致 RabbitMQ 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息，然后走第二个方案，到了晚上再补数据吧。

---

解决方案：

1、针对Rabbitmq可以使用惰性队列，让消息直接存储到磁盘中

2、增加消费者的数量，提升消费者的消费能力

---

#### 7、如果让你写一个消息队列，该如何进行架构设计？说一下思路

面试官心理分析

（1）你有没有对某一个消息队列做过较为深入的原理的了解，或者从整体了解把握住一个 RabbitMQ 的架构原理

（2）看看你的设计能力，给你一个常见的系统，就是消息队列系统，看看你能不能从全局把握一个整体架构设计，给出一些关键点出来

类似问题：如果让你来设计一个 spring 框架你会怎么做？如果让你来设计一个 Dubbo 框架你会怎么做？如果让你来设计一个 Mybatis 框架你会怎么做？

回答思路：

【1】首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统；【2】其次得考虑一下这个 mq 的数据要不要落地磁盘吧？只有落磁盘，才能保证别让进程挂了数据就丢了，那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，【3】其次得考虑一下 mq 的可用性；【4】最后是能不能支持数据不丢失

---

#### 8、导致的死信的几种原因？

1、消息被拒（Basic.Reject /Basic.Nack) 且 requeue = false。

2、消息TTL过期。

3、队列满了，无法再添加。

---

#### 9、什么是延迟队列以及具体的应用场景？

概述：存储对应的延迟消息，指当消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这

个消息进行消费。

应用场景：订单超时未支付，文章的延迟发送





